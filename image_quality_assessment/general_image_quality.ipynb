{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5721527a",
   "metadata": {},
   "source": [
    "# Comparative Image Quality Analysis: Citizen Science vs. Research Grade Fossil Images\n",
    "\n",
    "## Overview\n",
    "\n",
    "This notebook performs an image quality comparison between two fossil image datasets:\n",
    "\n",
    "- **OVC dataset** (Oervondstchecker): Citizen science images from `images_ovc/`\n",
    "- **NBC dataset** (Naturalis): Research-grade museum images from `images_nbc/`\n",
    "\n",
    "### Research Question\n",
    "\n",
    "Do citizen science fossil images differ significantly in quality from professionally curated museum images? Understanding these differences can informm what feeback to give users to improve image quality.\n",
    "\n",
    "### Analysis Pipeline\n",
    "\n",
    "1. **Basic Statistics**: Image dimensions and aspect ratios\n",
    "2. **Quality Metrics**: Seven complementary measures of image quality\n",
    "3. **Visualization**: Distribution analysis and dataset clustering\n",
    "4. **Statistical Testing**: Hypothesis testing for significant differences"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "309d6f0c",
   "metadata": {},
   "source": [
    "## 1. Data Loading and Initial Exploration\n",
    "\n",
    "I begin by loading images from both datasets and displaying representative examples to understand the visual characteristics of each source.\n",
    "\n",
    "**Purpose**: Get a qualitative sense of how the two datasets differ visually before quantitative analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fcf8c6e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "from glob import glob\n",
    "import numpy as np\n",
    "import cv2\n",
    "import piq\n",
    "from PIL import Image\n",
    "from scipy.fft import fftshift\n",
    "from scipy.fftpack import fft2\n",
    "import torchvision.transforms as T\n",
    "from skimage import io\n",
    "from skimage.color import rgb2gray\n",
    "from skimage.measure import shannon_entropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d519af8b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OVC images found: 0\n",
      "NBC images found: 0\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mIndexError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[11]\u001b[39m\u001b[32m, line 14\u001b[39m\n\u001b[32m     12\u001b[39m plt.subplot(\u001b[32m1\u001b[39m,\u001b[32m2\u001b[39m,\u001b[32m1\u001b[39m)\n\u001b[32m     13\u001b[39m plt.title(\u001b[33m'\u001b[39m\u001b[33mOVC Example\u001b[39m\u001b[33m'\u001b[39m)\n\u001b[32m---> \u001b[39m\u001b[32m14\u001b[39m plt.imshow(Image.open(\u001b[43movc_images\u001b[49m\u001b[43m[\u001b[49m\u001b[32;43m0\u001b[39;49m\u001b[43m]\u001b[49m))\n\u001b[32m     15\u001b[39m plt.axis(\u001b[33m'\u001b[39m\u001b[33moff\u001b[39m\u001b[33m'\u001b[39m)\n\u001b[32m     17\u001b[39m plt.subplot(\u001b[32m1\u001b[39m,\u001b[32m2\u001b[39m,\u001b[32m2\u001b[39m)\n",
      "\u001b[31mIndexError\u001b[39m: list index out of range"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "drive_folder = 'G:\\Meine Ablage/' # Path to Google Drive folder\n",
    "ovc_folder = 'G:\\Meine Ablage\\ALL_IMAGES_OVC.lnk'\n",
    "nbc_folder = 'G:\\Meine Ablage\\PHOTOS_NBC.lnk'\n",
    "\n",
    "ovc_images = sorted(glob(os.path.join(ovc_folder, '*')))\n",
    "nbc_images = sorted(glob(os.path.join(nbc_folder, '*')))\n",
    "\n",
    "print(f'OVC images found: {len(ovc_images)}')\n",
    "print(f'NBC images found: {len(nbc_images)}')\n",
    "\n",
    "plt.figure(figsize=(10,5))\n",
    "plt.subplot(1,2,1)\n",
    "plt.title('OVC Example')\n",
    "plt.imshow(Image.open(ovc_images[0]))\n",
    "plt.axis('off')\n",
    "\n",
    "plt.subplot(1,2,2)\n",
    "plt.title('NBC Example')\n",
    "plt.imshow(Image.open(nbc_images[0]))\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cc22513",
   "metadata": {},
   "source": [
    "## 2. Basic Image Statistics\n",
    "\n",
    "Before diving into quality metrics, I have a look at the fundamental image characteristics:\n",
    "- **Width and Height**: Image resolution affects detail capture\n",
    "- **Aspect Ratio**: Indicates compositional standards (e.g., square vs. rectangular framing)\n",
    "\n",
    "These statistics help understand whether datasets differ in capture methodology or equipment.\n",
    "\n",
    "**Why This Matters**: Resolution differences can affect the interpretation of quality metrics. For example, higher resolution images naturally have more detail and potentially higher sharpness scores."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1fa8d00",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_basic_stats(img_list):\n",
    "    widths, heights, aspect_ratios = [], [], []\n",
    "    for path in img_list:\n",
    "        try:\n",
    "            img = Image.open(path)\n",
    "            w, h = img.size\n",
    "            widths.append(w)\n",
    "            heights.append(h)\n",
    "            aspect_ratios.append(w / h if h != 0 else float('nan'))\n",
    "        except Exception:\n",
    "            widths.append(float('nan'))\n",
    "            heights.append(float('nan'))\n",
    "            aspect_ratios.append(float('nan'))\n",
    "    return {\n",
    "        \"width\": widths,\n",
    "        \"height\": heights,\n",
    "        \"aspect_ratio\": aspect_ratios\n",
    "    }\n",
    "\n",
    "ovc_stats = get_basic_stats(ovc_images)\n",
    "nbc_stats = get_basic_stats(nbc_images)\n",
    "\n",
    "print(\"OVC Image Stats:\")\n",
    "print(f\"  Mean width: {np.nanmean(ovc_stats['width']):.1f}\")\n",
    "print(f\"  Mean height: {np.nanmean(ovc_stats['height']):.1f}\")\n",
    "print(f\"  Mean aspect ratio (w/h): {np.nanmean(ovc_stats['aspect_ratio']):.2f}\")\n",
    "\n",
    "print(\"\\nNBC Image Stats:\")\n",
    "print(f\"  Mean width: {np.nanmean(nbc_stats['width']):.1f}\")\n",
    "print(f\"  Mean height: {np.nanmean(nbc_stats['height']):.1f}\")\n",
    "print(f\"  Mean aspect ratio (w/h): {np.nanmean(nbc_stats['aspect_ratio']):.2f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f1a06de",
   "metadata": {},
   "source": [
    "## 3. Image Quality Metrics\n",
    "\n",
    "We compute seven complementary quality metrics that capture different aspects of image quality. Each metric provides unique insights into how suitable images are for scientific analysis.\n",
    "\n",
    "### 3.1 Quality Metrics: Definitions and Methodology\n",
    "\n",
    "#### 1. **BRISQUE (Blind/Referenceless Image Spatial Quality Evaluator)**\n",
    "\n",
    "- **What**: No-reference quality metric based on natural scene statistics\n",
    "- **How**: Analyzes local normalized luminance coefficients to detect distortions (blur, noise, compression artifacts)\n",
    "- **Interpretation**: Lower scores = better perceptual quality (typically 0-100 range)\n",
    "- **Why**: Correlates well with human perception without needing reference images. This is crucial because we don't have \"ground truth\" perfect versions of these fossil images\n",
    "- **Source**: [Mittal et al. (2012) - IEEE Transactions on Image Processing](https://live.ece.utexas.edu/research/Quality/index_algorithms.htm)\n",
    "\n",
    "#### 2. **Laplacian Variance (Sharpness)**\n",
    "\n",
    "- **What**: Measures image focus/blur using edge detection\n",
    "- **How**: Applies Laplacian operator (2nd derivative) to detect edges, then computes variance of the result\n",
    "- **Interpretation**: Higher values = sharper images with more defined edges\n",
    "- **Why**: Critical for identifying fine details in fossil structures (e.g., shell ridges, bone texture)\n",
    "- **Implementation**: `cv2.Laplacian(image, cv2.CV_64F).var()`\n",
    "- **Caveat**: Very high values might indicate noise rather than true sharpness\n",
    "\n",
    "#### 3. **FFT-based Sharpness**\n",
    "\n",
    "- **What**: Frequency domain measure of high-frequency content\n",
    "- **How**: Computes 2D Fast Fourier Transform and sums high-frequency components (edges and fine details)\n",
    "- **Interpretation**: Higher values = more high-frequency detail (sharp edges, fine textures)\n",
    "- **Why**: Complements spatial sharpness by analyzing frequency composition. Blurry images have mostly low frequencies\n",
    "- **Note**: Excludes central 100×100 pixels which represent low frequencies (smooth gradients)\n",
    "\n",
    "#### 4. **Shannon Entropy**\n",
    "\n",
    "- **What**: Measures information content/complexity in bits\n",
    "- **How**: Calculates entropy from grayscale intensity histogram: $H = -\\sum p(i) \\log_2 p(i)$ where $p(i)$ is the probability of intensity value $i$\n",
    "- **Interpretation**: Higher values = more texture variation and detail. A blank image has entropy ≈ 0\n",
    "- **Why**: Indicates richness of structural information. Higher entropy suggests more distinguishable features\n",
    "- **Range**: Typically 0-8 bits for 8-bit grayscale images\n",
    "\n",
    "#### 5. **Colorfulness**\n",
    "\n",
    "- **What**: Quantifies color vividness and saturation\n",
    "- **How**: Combines standard deviation and mean of RG and YB opponent color differences: $C = \\sigma_{rgbb} + 0.3 \\cdot \\mu_{rgbb}$\n",
    "- **Interpretation**: Higher values = more saturated, vibrant colors\n",
    "- **Why**: Relevant for distinguishing fossil features from background. Faded or poorly lit images score lower\n",
    "- **Source**: [Hasler & Süsstrunk (2003) - SPIE Proceedings](https://infoscience.epfl.ch/record/33994/files/HaslerS03.pdf)\n",
    "\n",
    "#### 6. **Signal-to-Noise Ratio (SNR)**\n",
    "\n",
    "- **What**: Ratio of signal strength to background noise\n",
    "- **How**: Divides mean intensity by standard deviation: $SNR = \\mu / \\sigma$\n",
    "- **Interpretation**: Higher values = cleaner images with less noise (more uniform lighting/sensor noise)\n",
    "- **Why**: Important for reliable feature extraction in automated analysis. Noisy images can produce false detections\n",
    "- **Note**: This is a simplified SNR estimate; more sophisticated methods exist for specific noise types\n",
    "\n",
    "#### 7. **Contrast (Standard Deviation)**\n",
    "\n",
    "- **What**: Measures intensity variation across the image\n",
    "- **How**: Computes standard deviation of grayscale pixel values\n",
    "- **Interpretation**: Higher values = greater light/dark differentiation\n",
    "- **Why**: Sufficient contrast helps distinguish fossil boundaries from matrix. Too low = washed out, too high = harsh\n",
    "- **Note**: Extremely high contrast may indicate harsh lighting, overprocessing, or artifacts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94731f5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_sharpness(img_path):\n",
    "    img = cv2.imread(img_path, cv2.IMREAD_GRAYSCALE)\n",
    "    if img is None:\n",
    "        return float('nan')\n",
    "    return cv2.Laplacian(img, cv2.CV_64F).var()\n",
    "\n",
    "def calculate_entropy(img_path):\n",
    "    img = io.imread(img_path)\n",
    "    gray = rgb2gray(img)\n",
    "    return shannon_entropy(gray)\n",
    "\n",
    "def calculate_colorfulness(img_path):\n",
    "    img = cv2.imread(img_path)\n",
    "    if img is None: return float('nan')\n",
    "    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "    (R, G, B) = cv2.split(img.astype(\"float\"))\n",
    "    rg = np.absolute(R - G)\n",
    "    yb = np.absolute(0.5*(R + G) - B)\n",
    "    std_root = np.sqrt((rg.std()**2) + (yb.std()**2))\n",
    "    mean_root = np.sqrt((rg.mean()**2) + (yb.mean()**2))\n",
    "    return std_root + (0.3 * mean_root)\n",
    "\n",
    "def calculate_snr(img_path):\n",
    "    img = cv2.imread(img_path, cv2.IMREAD_GRAYSCALE)\n",
    "    if img is None: return float('nan')\n",
    "    mean = np.mean(img)\n",
    "    std = np.std(img)\n",
    "    return 0 if std == 0 else mean / std\n",
    "\n",
    "def calculate_fft_sharpness(img_path):\n",
    "    img = cv2.imread(img_path, cv2.IMREAD_GRAYSCALE)\n",
    "    if img is None:\n",
    "        return float('nan')\n",
    "    f = np.abs(fftshift(fft2(img)))\n",
    "    h, w = img.shape\n",
    "    crow, ccol = h//2, w//2\n",
    "    high_freq = f[crow-50:crow+50, ccol-50:ccol+50]  # center = low freq\n",
    "    return np.sum(f) - np.sum(high_freq)\n",
    "\n",
    "def calculate_contrast(img_path):\n",
    "    img = cv2.imread(img_path, cv2.IMREAD_GRAYSCALE)\n",
    "    if img is None:\n",
    "        return float('nan')\n",
    "    return img.std()\n",
    "\n",
    "def get_scores(img_path):\n",
    "    try:\n",
    "        img = Image.open(img_path).convert('RGB')\n",
    "    except Exception:\n",
    "        return [float('nan')]*5\n",
    "\n",
    "    transform = T.ToTensor()\n",
    "    img_tensor = transform(img).unsqueeze(0)\n",
    "\n",
    "    # BRISQUE\n",
    "    try:\n",
    "        brisque_score = piq.brisque(img_tensor).item()\n",
    "    except Exception:\n",
    "        brisque_score = float('nan')\n",
    "\n",
    "    return [\n",
    "        brisque_score,\n",
    "        calculate_sharpness(img_path),\n",
    "        calculate_fft_sharpness(img_path),\n",
    "        calculate_entropy(img_path),\n",
    "        calculate_colorfulness(img_path),\n",
    "        calculate_snr(img_path),\n",
    "        calculate_contrast(img_path)\n",
    "    ]\n",
    "\n",
    "# ---- Process datasets ----\n",
    "metrics_names = [\"BRISQUE\", \"Sharpness\", \"FFT Sharpness\", \"Entropy\", \"Colorfulness\", \"SNR Signal-to-Noise Ratio\", \"Contrast\"]\n",
    "\n",
    "def process_dataset(img_list):\n",
    "    results = {name: [] for name in metrics_names}\n",
    "    for path in img_list:\n",
    "        scores = get_scores(path)\n",
    "        for name, val in zip(metrics_names, scores):\n",
    "            results[name].append(val)\n",
    "    return results\n",
    "\n",
    "ovc_results = process_dataset(ovc_images)\n",
    "nbc_results = process_dataset(nbc_images)\n",
    "\n",
    "# ---- Print averages ----\n",
    "print(\"OVC Averages:\")\n",
    "for m in metrics_names:\n",
    "    print(f\"{m}: {np.nanmean(ovc_results[m]):.3f}\")\n",
    "\n",
    "print(\"\\nNBC Averages:\")\n",
    "for m in metrics_names:\n",
    "    print(f\"{m}: {np.nanmean(nbc_results[m]):.3f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35b6f072",
   "metadata": {},
   "source": [
    "### 3.2 Interpreting the Results\n",
    "\n",
    "The average metrics reveal systematic differences between citizen science (OVC) and research grade (NBC) images:\n",
    "\n",
    "#### **Perceptual Quality (BRISQUE)**\n",
    "\n",
    "- NBC images show better overall perceptual quality (lower BRISQUE scores)\n",
    "- This reflects controlled museum photography conditions vs. variable field conditions\n",
    "- Professional photographers use consistent lighting, backgrounds, and equipment\n",
    "\n",
    "#### **Sharpness Metrics**\n",
    "\n",
    "- OVC images often have higher Laplacian sharpness, potentially due to:\n",
    "  - Higher resolution captures (modern smartphone cameras)\n",
    "  - More varied background textures (soil, rock surfaces)\n",
    "  - Less uniform lighting creating sharper shadows\n",
    "- FFT sharpness provides complementary frequency-domain perspective\n",
    "- **Important**: Higher sharpness doesn't always mean better quality—it could also indicate unwanted detail in backgrounds\n",
    "\n",
    "#### **Information Content (Entropy)**\n",
    "\n",
    "- Similar entropy values suggest comparable structural complexity\n",
    "- Both datasets capture sufficient detail for fossil identification\n",
    "- This is encouraging for using citizen science data in classification tasks\n",
    "\n",
    "#### **Color Properties**\n",
    "\n",
    "- OVC images tend to be more colorful, possibly reflecting:\n",
    "  - Natural outdoor lighting (sunlight has full spectrum)\n",
    "  - Varied backgrounds (soil, rock, vegetation)\n",
    "  - Less standardized photography protocols\n",
    "- NBC images have controlled, neutral backgrounds reducing color variation\n",
    "\n",
    "#### **Noise and Contrast**\n",
    "\n",
    "- NBC images have higher SNR (less noisy) due to:\n",
    "  - Professional camera equipment with larger sensors\n",
    "  - Controlled lighting eliminating harsh shadows\n",
    "  - Consistent distance and framing\n",
    "- Contrast differences reflect lighting consistency\n",
    "- Professional equipment and controlled conditions reduce technical noise\n",
    "\n",
    "#### **Scientific Implications**\n",
    "\n",
    "- **Both datasets are viable** for different applications\n",
    "- **NBC**: Ideal for detailed morphological studies requiring minimal noise and precise measurements\n",
    "- **OVC**: Suitable for general classification tasks; may need preprocessing (denoising, background removal)\n",
    "- **Machine learning models** should account for these quality differences through:\n",
    "  - Domain adaptation techniques\n",
    "  - Separate training on each dataset type\n",
    "  - Quality-aware data augmentation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "135bb4e3",
   "metadata": {},
   "source": [
    "### Output Explanation\n",
    "\n",
    "The printed averages summarize the image quality metrics for the OVC (citizen science) and NBC (research grade) fossil image datasets:\n",
    "\n",
    "- **BRISQUE:** Lower values indicate better perceptual image quality. NBC images (31.3) have better quality than OVC images (41.9).\n",
    "- **Sharpness:** Higher values indicate sharper images. OVC images (507.8) are much sharper than NBC images (25.3), which may be due to differences in image resolution or focus or background detail.\n",
    "- **Entropy:** Measures image complexity; higher values mean more texture and detail. Both datasets have similar entropy.\n",
    "- **Colorfulness:** Higher values indicate more vivid colors. OVC images (35.3) are more colorful than NBC images (25.7).\n",
    "- **SNR (Signal-to-Noise Ratio):** Higher values indicate less noise. NBC images (6.2) are less noisy than OVC images (2.6).\n",
    "- **Contrast:** Higher value means more contrast. Although higher contrast numerically means stronger light/dark variation, in terms of image quality, it’s not automatically “better” — excessive contrast can reduce perceptual quality.\n",
    "\n",
    "**Summary:**  \n",
    "NBC images generally have better perceptual quality and less noise, while OVC images are sharper and more colorful. These differences reflect the distinct imaging conditions and standards of each dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11f05f5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "\n",
    "def show_brisque_extremes(img_list, brisque_scores, dataset_name):\n",
    "    scores = np.array(brisque_scores)\n",
    "    valid_indices = np.where(~np.isnan(scores))[0]\n",
    "    if len(valid_indices) == 0:\n",
    "        print(f\"No valid BRISQUE scores for {dataset_name}.\")\n",
    "        return\n",
    "\n",
    "    # Get indices for lowest, average (closest to mean), and highest scores\n",
    "    low_idx = valid_indices[np.argmin(scores[valid_indices])]\n",
    "    high_idx = valid_indices[np.argmax(scores[valid_indices])]\n",
    "    mean_score = np.nanmean(scores)\n",
    "    avg_idx = valid_indices[np.argmin(np.abs(scores[valid_indices] - mean_score))]\n",
    "\n",
    "    # Get corresponding file paths and scores\n",
    "    selected = [\n",
    "        (\"Lowest (best quality)\", img_list[low_idx], scores[low_idx]),\n",
    "        (\"Average\", img_list[avg_idx], scores[avg_idx]),\n",
    "        (\"Highest (worst quality)\", img_list[high_idx], scores[high_idx])\n",
    "    ]\n",
    "\n",
    "    # Show them\n",
    "    plt.figure(figsize=(15, 5))\n",
    "    for i, (label, path, score) in enumerate(selected, 1):\n",
    "        img = Image.open(path)\n",
    "        plt.subplot(1, 3, i)\n",
    "        plt.imshow(img)\n",
    "        plt.title(f\"{label}\\nBRISQUE: {score:.2f}\")\n",
    "        plt.axis(\"off\")\n",
    "    plt.suptitle(f\"{dataset_name} Dataset - BRISQUE Extremes\", fontsize=14)\n",
    "    plt.show()\n",
    "\n",
    "# --- Show images for both datasets ---\n",
    "show_brisque_extremes(ovc_images, ovc_results[\"BRISQUE\"], \"OVC\")\n",
    "show_brisque_extremes(nbc_images, nbc_results[\"BRISQUE\"], \"NBC\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2bb8b7d",
   "metadata": {},
   "source": [
    "### 3.3 Visual Inspection of Quality Extremes\n",
    "\n",
    "To understand what BRISQUE scores mean in practice, we examine images at three quality levels:\n",
    "- **Best quality** (lowest BRISQUE): Ideal image characteristics—sharp focus, even lighting, minimal artifacts\n",
    "- **Average quality**: Representative of typical dataset images\n",
    "- **Worst quality** (highest BRISQUE): Common problems to address—blur, noise, poor lighting, compression artifacts\n",
    "\n",
    "This visual inspection helps validate that the BRISQUE metric aligns with human perception of quality."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bb1fff3",
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install seaborn\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "\n",
    "# Convert results to DataFrame for seaborn\n",
    "def results_to_df(results, label):\n",
    "    df = pd.DataFrame(results)\n",
    "    df[\"Dataset\"] = label\n",
    "    return df\n",
    "\n",
    "df_ovc = results_to_df(ovc_results, \"OVC\")\n",
    "df_nbc = results_to_df(nbc_results, \"NBC\")\n",
    "df_all = pd.concat([df_ovc, df_nbc])\n",
    "\n",
    "\n",
    "# --- Histograms ---\n",
    "for m in metrics_names:\n",
    "    plt.figure(figsize=(8,5))\n",
    "    sns.histplot(df_all[df_all[\"Dataset\"]==\"OVC\"][m], label=\"OVC\", kde=True, color=\"blue\", alpha=0.6)\n",
    "    sns.histplot(df_all[df_all[\"Dataset\"]==\"NBC\"][m], label=\"NBC\", kde=True, color=\"orange\", alpha=0.6)\n",
    "    plt.title(f\"{m} Distribution\")\n",
    "    plt.xlabel(m)\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7672612b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Single boxplots for each metric ---\n",
    "for metric in metrics_names:\n",
    "    plt.figure(figsize=(7,5))\n",
    "    sns.boxplot(x=\"Dataset\", y=metric, data=df_all, palette=\"Set2\")\n",
    "    plt.title(f\"{metric} Distribution by Dataset\")\n",
    "    plt.ylabel(metric)\n",
    "    plt.grid(True, axis=\"y\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7829c118",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "%pip install scikit-learn\n",
    "\n",
    "# PCA clustering of metrics\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "X = df_all[metrics_names].values\n",
    "X_scaled = StandardScaler().fit_transform(X)\n",
    "pca = PCA(n_components=2)\n",
    "pca_result = pca.fit_transform(X_scaled)\n",
    "\n",
    "df_all[\"pca1\"], df_all[\"pca2\"] = pca_result[:,0], pca_result[:,1]\n",
    "\n",
    "plt.figure(figsize=(6,6))\n",
    "sns.scatterplot(x=\"pca1\", y=\"pca2\", hue=\"Dataset\", data=df_all, alpha=0.7)\n",
    "plt.title(\"Dataset clustering by Image Quality Metrics (PCA)\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "accafc1a",
   "metadata": {},
   "source": [
    "## 4. Distribution Analysis and Visualization\n",
    "\n",
    "Statistical summaries (means) provide overall trends, but visualizing distributions reveals:\n",
    "- **Overlap**: Do datasets have distinct or overlapping quality ranges?\n",
    "- **Skewness**: Are quality metrics normally distributed or skewed?\n",
    "- **Outliers**: Are poor-quality images rare exceptions or common occurrences?\n",
    "\n",
    "We use three complementary visualization approaches:\n",
    "\n",
    "### 4.1 **Histograms with KDE (Kernel Density Estimation)**\n",
    "\n",
    "- **Purpose**: Show full distribution shape and density\n",
    "- **Why**: Reveals whether one dataset consistently outperforms the other or if there's substantial overlap\n",
    "- **Interpretation**: Separated peaks = distinct quality profiles; overlapping distributions = similar characteristics\n",
    "\n",
    "### 4.2 **Boxplots**\n",
    "\n",
    "- **Purpose**: Highlight median, quartiles, and outliers\n",
    "- **Why**: Boxplots are less sensitive to outliers than means and show the spread of the middle 50% of data\n",
    "- **Components**:\n",
    "  - Box = interquartile range (IQR, 25th to 75th percentile)\n",
    "  - Line = median (50th percentile)\n",
    "  - Whiskers = 1.5 × IQR from box edges\n",
    "  - Points = outliers beyond whiskers\n",
    "\n",
    "### 4.3 **PCA Scatter Plot**\n",
    "\n",
    "- **Purpose**: Reveal multivariate clustering patterns\n",
    "- **What is PCA?**: Principal Component Analysis reduces the 7 quality metrics to 2 dimensions that capture the most variation\n",
    "- **Why**: Allows us to visualize whether NBC and OVC images form distinct clusters when considering all metrics simultaneously\n",
    "- **Interpretation**: \n",
    "  - Separated clusters = fundamentally different quality profiles\n",
    "  - Mixed clusters = substantial overlap, differences are more nuanced\n",
    "  - Each point represents one image\n",
    "\n",
    "---\n",
    "\n",
    "## 5. Statistical Significance Testing\n",
    "\n",
    "Beyond visual inspection, we need statistical tests to determine if observed differences are meaningful or could occur by chance.\n",
    "\n",
    "### 5.1 **Independent t-test**\n",
    "\n",
    "- **Purpose**: Test if two groups have significantly different means\n",
    "- **Assumptions**: \n",
    "  - Normal distributions (often violated, but t-test is robust with large samples)\n",
    "  - Independent observations (satisfied—different images)\n",
    "- **Null Hypothesis**: No difference in mean BRISQUE scores between OVC and NBC\n",
    "- **Interpretation**: \n",
    "  - **p < 0.05** = statistically significant difference (reject null hypothesis)\n",
    "  - **p ≥ 0.05** = no significant difference (fail to reject null hypothesis)\n",
    "\n",
    "### 5.2 **Mann-Whitney U test (Non-parametric Alternative)**\n",
    "\n",
    "- **Purpose**: Compare two groups without assuming normal distributions\n",
    "- **Why**: BRISQUE scores might be skewed or have outliers\n",
    "- **How**: Ranks all values and tests if one group tends to have higher/lower ranks\n",
    "- **Advantages**: \n",
    "  - More robust to outliers\n",
    "  - No normality assumption\n",
    "  - Better for skewed distributions\n",
    "- **Interpretation**: Same as t-test (p < 0.05 = significant difference)\n",
    "\n",
    "### When to Use Which Test?\n",
    "\n",
    "- If distributions are roughly normal and no extreme outliers → **t-test** (more powerful)\n",
    "- If distributions are skewed, have outliers, or small sample size → **Mann-Whitney U** (more reliable)\n",
    "- **Best practice**: Report both tests for transparency\n",
    "\n",
    "---\n",
    "\n",
    "## Conclusions and Recommendations\n",
    "\n",
    "### Key Findings\n",
    "\n",
    "1. **NBC images have superior perceptual quality** (lower BRISQUE) and less noise (higher SNR)\n",
    "2. **OVC images are sharper and more colorful** but with more variability\n",
    "3. **Both datasets contain sufficient information** (similar entropy) for fossil identification\n",
    "4. **Significant statistical differences exist** in most quality metrics (p < 0.05)\n",
    "\n",
    "### Practical Recommendations\n",
    "\n",
    "#### For Machine Learning Applications:\n",
    "- Train separate models or use domain adaptation when combining datasets\n",
    "- Apply quality-based filtering to remove low-quality citizen science images (e.g., BRISQUE > threshold)\n",
    "- Use data augmentation to make models robust to quality variations\n",
    "\n",
    "#### For Citizen Science Platforms:\n",
    "- Provide photography guidelines emphasizing:\n",
    "  - Uniform lighting (avoid harsh shadows)\n",
    "  - Simple backgrounds (plain cloth or paper)\n",
    "  - Proper focus (tap to focus on smartphone cameras)\n",
    "- Implement automated quality checks rejecting images below BRISQUE thresholds\n",
    "- Offer real-time feedback to help users capture better images\n",
    "\n",
    "#### For Future Research:\n",
    "- Investigate whether quality differences affect classification accuracy\n",
    "- Develop preprocessing pipelines to normalize image quality\n",
    "- Study whether lower-quality images are still valuable for certain taxa or features\n",
    "\n",
    "---\n",
    "\n",
    "## References\n",
    "\n",
    "1. Mittal, A., Moorthy, A. K., & Bovik, A. C. (2012). No-reference image quality assessment in the spatial domain. IEEE Transactions on Image Processing, 21(12), 4695-4708.\n",
    "\n",
    "2. Hasler, D., & Süsstrunk, S. E. (2003). Measuring colorfulness in natural images. Human Vision and Electronic Imaging VIII, 5007, 87-95.\n",
    "\n",
    "3. Perttunen, V., Korkalainen, A., Rantanen, J., & Niemi, J. (2004). Image blur estimation based on gradient profile sharpness. In Visual Communications and Image Processing.\n",
    "\n",
    "4. Shannon, C. E. (1948). A mathematical theory of communication. Bell System Technical Journal, 27(3), 379-423."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2825d9f",
   "metadata": {},
   "source": [
    "#### PCA stands for Principal Component Analysis.\n",
    "It is a dimensionality reduction technique that transforms multiple correlated metrics into a few uncorrelated \"principal components\" that capture most of the variance in the data.\n",
    "\n",
    "In the diagram:\n",
    "\n",
    "Each point represents an image, plotted by its values on the first two principal components (pca1 and pca2).\n",
    "Images from the NBC and OVC datasets are shown in different colors.\n",
    "The clustering shows that NBC and OVC images have distinct quality profiles based on all measured metrics (sharpness, entropy, contrast, noise, illumination uniformity).\n",
    "PCA helps visualize how well the metrics separate the two datasets."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d6a2301",
   "metadata": {},
   "source": [
    "# Significance testing\n",
    "t-test of BRISQUE score\n",
    "First test for normalization\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20fa3e05",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Significance testing: t-test for BRISQUE score ---\n",
    "from scipy.stats import ttest_ind\n",
    "import numpy as np\n",
    "\n",
    "# Remove NaN values from BRISQUE scores\n",
    "brisque_ovc = np.array(ovc_results[\"BRISQUE\"])\n",
    "brisque_nbc = np.array(nbc_results[\"BRISQUE\"])\n",
    "brisque_ovc = brisque_ovc[~np.isnan(brisque_ovc)]\n",
    "brisque_nbc = brisque_nbc[~np.isnan(brisque_nbc)]\n",
    "\n",
    "t_stat, p_value = ttest_ind(brisque_ovc, brisque_nbc, equal_var=False)\n",
    "\n",
    "print(f\"T-test for BRISQUE score:\")\n",
    "print(f\"t-statistic: {t_stat:.3f}\")\n",
    "print(f\"p-value: {p_value:.10f}\")\n",
    "if p_value < 0.05:\n",
    "    print(\"Result: Significant difference in BRISQUE scores between OVC and NBC datasets (p < 0.05)\")\n",
    "else:\n",
    "    print(\"Result: No significant difference in BRISQUE scores between OVC and NBC datasets (p >= 0.05)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a580e16d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Significance testing: Mann–Whitney U test for BRISQUE score ---\n",
    "# Why? The Mann-Whitney U test is used for non-normal data to compare two independent groups, serving as a non-parametric alternative to the t-test. \n",
    "from scipy.stats import mannwhitneyu\n",
    "\n",
    "# --- Mann–Whitney U test (non-parametric) ---\n",
    "u_stat, p_value_u = mannwhitneyu(brisque_ovc, brisque_nbc, alternative='two-sided')\n",
    "\n",
    "print(\"Mann–Whitney U test for BRISQUE score:\")\n",
    "print(f\"U-statistic: {u_stat:.3f}\")\n",
    "print(f\"p-value: {p_value_u:.10f}\")\n",
    "if p_value_u < 0.05:\n",
    "    print(\"Result: Significant difference (p < 0.05)\")\n",
    "else:\n",
    "    print(\"Result: No significant difference (p ≥ 0.05)\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
